{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getty TGN | check on longitudes and latitudes by cross-checking other sources\n",
    "- 2024-05-18\n",
    "- Geo check on Getty TGN data fetched via SPARQL-endpoint\n",
    "- https://amandinancy16.medium.com/reverse-geocoding-with-geopy-c26cfb63f74c\n",
    "- V. Martens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating time stamps\n",
    "import time\n",
    "\n",
    "# importing files\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# progress bar\n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# regex module\n",
    "import re\n",
    "\n",
    "# for multi-threading\n",
    "from concurrent import futures\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import multiprocessing as mp\n",
    "\n",
    "# retrieve country names from country codes\n",
    "import pycountry\n",
    "\n",
    "# data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# back up files\n",
    "import pickle\n",
    "\n",
    "# retrieve various geo locations\n",
    "import reverse_geocoder as rg\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# measure distance between two geo points\n",
    "from haversine import haversine, Unit\n",
    "\n",
    "# save and dump\n",
    "import pickle\n",
    "\n",
    "# surpress, warnings, uhoohhhh\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# preferences\n",
    "# adjust pandas to show all cols\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest_file(filepath:str) -> str:\n",
    "    '''\n",
    "    loads created latest create file from a directory\n",
    "    args: string with filepath\n",
    "    returns: latest file from a list of files\n",
    "    '''\n",
    "\n",
    "    list_of_files = glob.glob(filepath)\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    print(latest_file)\n",
    "    \n",
    "    return latest_file\n",
    "\n",
    "def join_lats_lons(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    args: pd.DataFrame with lats and lons\n",
    "    returns: pd.DataFrame with corrected lats and lons and joined into one col \n",
    "    '''\n",
    "    \n",
    "    df['lat'] = df['lat'].str.replace('-.','-0.')\n",
    "    df['lon'] = df['lon'].str.replace('-.','-0.')\n",
    "    df['coordinates'] = list(zip(df['lat'], df['lon']))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_country(df:pd.DataFrame, i:int) -> list:\n",
    "\n",
    "    '''\n",
    "    args: pd.DataFrame() with coordinates column\n",
    "    returns: a list with dicts with geo locations, every dict contains keys with country name, 3 admin names, lat, lon\n",
    "    '''\n",
    "    \n",
    "    results = rg.search(df['coordinates'].iloc[i])\n",
    "\n",
    "    for item in results:\n",
    "        query = df['coordinates'].iloc[i]\n",
    "        tgn_id = df['tgn_id'].iloc[i]\n",
    "        country = item['cc']\n",
    "        looked_lat = item['lat']\n",
    "        looked_lon = item['lon']\n",
    "        looked_name = item['name']\n",
    "        \n",
    "    return [tgn_id, query, country, looked_lat, looked_lon, looked_name]\n",
    "\n",
    "def parse_reverse_geo_lookup(list_of_dicts:list) -> pd.DataFrame:\n",
    "    '''\n",
    "    args: a list with dicts with geo locations\n",
    "    returns: pd.DataFrame() with parsed geo locations\n",
    "    '''\n",
    "    \n",
    "    dfs = pd.DataFrame()\n",
    "\n",
    "    for coord_dict in list_of_dicts:\n",
    "        df = pd.DataFrame(coord_dict).T\n",
    "        dfs = pd.concat([dfs, df])\n",
    "    \n",
    "    dfs = dfs.rename(columns={0 : 'tgn_id_lookup',\n",
    "                              1 : 'query_look_up',\n",
    "                              2 : 'country_code_lookup', \n",
    "                              3 : 'lat_lookup',\n",
    "                              4 : 'lon_lookup', \n",
    "                              5 : 'municipality_lookup'})\n",
    "    \n",
    "    return dfs\n",
    "    \n",
    "def parse_parentstring(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    parses out info from parentstring\n",
    "    args: pd.DataFrame() with tgn parentstrings\n",
    "    returns: pd.DataFrame() with reordered and parsed columns\n",
    "    '''\n",
    "    \n",
    "    df['parentstring_province'] = (df['parentstring']\n",
    "                                    .str.split(',')\n",
    "                                    .str[0]\n",
    "                                    .str.strip())\n",
    "    \n",
    "    df['parentstring_country'] = (df['parentstring']\n",
    "                                    .str.split(',')\n",
    "                                    .str[1]\n",
    "                                    .str.strip())\n",
    "    \n",
    "    df['parentstring_continent'] = (df['parentstring']\n",
    "                                    .str.split(',')\n",
    "                                    .str[2]\n",
    "                                    .str.strip())  \n",
    "    \n",
    "    df['parentstring_world'] = (df['parentstring']\n",
    "                                    .str.split(',')\n",
    "                                    .str[3]\n",
    "                                    .str.strip())  \n",
    "    \n",
    "    df = df[['tgn_id', 'city_name', 'inferred_city_name', 'parentstring_province',\n",
    "             'parentstring_country', 'parentstring_continent', 'parentstring_world',\n",
    "             'broader_parentstring', 'lat', 'lon', 'coordinates', 'query_look_up',\n",
    "             'country_code_lookup', 'lat_lookup', 'lon_lookup',\n",
    "             'municipality_lookup']]\n",
    "    \n",
    "    return df    \n",
    "\n",
    "def parse_broader_parentstring(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    parses out info from broader parentstring\n",
    "    args: pd.DataFrame() with tgn broader parentstrings\n",
    "    returns: pd.DataFrame() with reordered and parsed columns\n",
    "    '''\n",
    "    \n",
    "    df['broader_parentstring_country'] = (df['broader_parentstring']\n",
    "                                    .str.split()\n",
    "                                    .str[0]\n",
    "                                    .str.replace(',','')\n",
    "                                    .str.strip())\n",
    "    \n",
    "    df['broader_parentstring_continent'] = (df['broader_parentstring']\n",
    "                                    .str.split()\n",
    "                                    .str[1]\n",
    "                                    .str.replace(',','')\n",
    "                                    .str.strip())  \n",
    "    \n",
    "    df['broader_parentstring_world'] = (df['broader_parentstring']\n",
    "                                    .str.split()\n",
    "                                    .str[2]\n",
    "                                    .str.replace(',','')\n",
    "                                    .str.strip())  \n",
    "    \n",
    "    df = df[['tgn_id', 'city_name', 'inferred_city_name', 'parentstring_province',\n",
    "       'parentstring_country', 'parentstring_continent', 'parentstring_world',\n",
    "       'broader_parentstring_country', 'broader_parentstring_continent',\n",
    "       'broader_parentstring_world', 'lat', 'lon', 'coordinates', 'query_look_up',\n",
    "       'country_code_lookup', 'lat_lookup', 'lon_lookup', 'municipality_lookup']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def country_code_lookup(country_code:str) -> str:\n",
    "    '''\n",
    "    \n",
    "    retrieves countryname from countrycode\n",
    "    args: string with countrycode\n",
    "    returns: returns country name\n",
    "    '''\n",
    "    return pycountry.countries.get(alpha_2=country_code).name\n",
    "\n",
    "def municipality_look_up(df:pd.DataFrame) -> dict:\n",
    "    '''\n",
    "    pd.DataFrame with city names retrieves city info, lats, lons\n",
    "    args: pd.DataFrame with city name/municipalities\n",
    "    returns: a dict with city names as keys and location info and lats, lons as values\n",
    "    '''\n",
    "    geolocator = Nominatim(user_agent=\"Nancy Amandi\", timeout=10)\n",
    "    \n",
    "    dict_locs = {}\n",
    "    \n",
    "    for i in tqdm(range(len(df)), total=len(df), desc='find geo info based on city names'):\n",
    "        dict_locs[df['municipality_lookup'].iloc[i]] = geolocator.geocode(df['municipality_lookup'].iloc[i])\n",
    "    \n",
    "    return dict_locs\n",
    "\n",
    "def parse_geo_lookup(results_lookup:dict) -> pd.DataFrame:\n",
    "    '''\n",
    "    parses looked up geo data into a pd.DataFrame\n",
    "    args: a dict with looked up geo locations based on city names\n",
    "    returns: a pd.DataFrame with city names, lat-lons\n",
    "    '''\n",
    "    df_parsed_geo = (pd.DataFrame(results_lookup)\n",
    "                    .T.reset_index()\n",
    "                    .rename(columns={'index':'query_city_name',\n",
    "                                    0 : 'query_city_city_info',\n",
    "                                    1 : 'query_city_geo_data'}))\n",
    "    \n",
    "    return df_parsed_geo\n",
    "\n",
    "def data_haversine_tuple_creator(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    args: pd.DataFrame with seperate lat lon\n",
    "    returns: pd.Dataframe with a tuple of lat lon in one col\n",
    "    '''\n",
    "    \n",
    "    df['coordinates_looked_up'] = list(zip(df['lat_lookup'].astype(float), df['lon_lookup'].astype(float)))\n",
    "    df = df.drop(columns=['lat_lookup', 'lon_lookup'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def haversine_distance_calculator(df) -> pd.DataFrame:\n",
    "    '''\n",
    "    measures distance between two tuples containing two geo points each \n",
    "    args: a pd.DataFrame with two columns containing tuples with floats\n",
    "    returns: a pd.DataFrame with a column that has measured the difference in kms between two tuples with geo points\n",
    "    '''\n",
    "    df['km_difference'] = '' \n",
    "    \n",
    "    for i in tqdm(range(len(df)), total=len(df), desc='find geo info based on city names'):\n",
    "        df['km_difference'].iloc[i] = round(haversine(df['query_city_geo_data'].iloc[i], df['coordinates_looked_up'].iloc[i], unit=Unit.KILOMETERS),2)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240607-143032_df_errors_tgn.pickle, 20240607-143032_df_lod_results_tgn.pickle, 20240607-143032_loc_check_TGN.xlsx\n"
     ]
    }
   ],
   "source": [
    "# create back up filename for a pickle\n",
    "time_stamp = time.strftime('%Y%m%d-%H%M%S')\n",
    "filename_df_errors = f'{time_stamp}_df_errors_tgn.pickle'\n",
    "\n",
    "# create back up filename for a pickle\n",
    "time_stamp = time.strftime('%Y%m%d-%H%M%S')\n",
    "filename_df_lod_results = f'{time_stamp}_df_lod_results_tgn.pickle'\n",
    "\n",
    "# create back up filename for a pickle\n",
    "time_stamp = time.strftime('%Y%m%d-%H%M%S')\n",
    "filename_excel_export = f'{time_stamp}_loc_check_TGN.xlsx'\n",
    "\n",
    "# country_check \n",
    "country = 'Netherlands'\n",
    "continent = 'Europe'\n",
    "\n",
    "print(f\"{filename_df_errors}, {filename_df_lod_results}, {filename_excel_export}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dumps\\results_df_tgn_country.pickle\n"
     ]
    }
   ],
   "source": [
    "latest_picke_file = load_latest_file('data_dumps/*tgn_country.pickle')\n",
    "\n",
    "# Open the file in binary mode\n",
    "with open(latest_picke_file, 'rb') as file:\n",
    "      \n",
    "    # Call load method to deserialze\n",
    "    df_tgn = pickle.load(file)\n",
    "    \n",
    "# enrich lats, lons\n",
    "df_tgn = join_lats_lons(df_tgn)\n",
    "df_tgn.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset data\n",
    "df_nl = df_tgn[(df_tgn['broader_parentstring'].str.contains(f'{country}') == True)]\n",
    "df_europe = df_tgn[(df_tgn['broader_parentstring'].str.contains(f'{europe}') == True)]\n",
    "df_nl.shape, df_europe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geo data-check\n",
    " 1. Reverse city look-up on geo lats + lons \n",
    " 1. Retrieve lats, lons based on reversed look-up\n",
    " 1. Compare distances between two geo-points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...\n",
      "Loading formatted geocoded file...\n",
      "Loading formatted geocoded file...\n",
      "Loading formatted geocoded file...\n",
      "Loading formatted geocoded file...\n",
      "Loading formatted geocoded file...\n",
      "Loading formatted geocoded file...\n",
      "Loading formatted geocoded file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "find reverse geo codes:  53%|█████▎    | 1032/1947 [37:17<22:06,  1.45s/it] "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import multiprocessing as mp\n",
    "pools = mp.cpu_count()\n",
    "\n",
    "# Start pool\n",
    "thread_pool = ThreadPoolExecutor(max_workers=pools, thread_name_prefix = 'thread')\n",
    "\n",
    "# reate futures\n",
    "futures = [thread_pool.submit(get_country, df_nl, i) for i in range(len(df_nl))]\n",
    "\n",
    "# submit tasks\n",
    "results = [future.result() for future in tqdm(futures, total=len(futures), desc='find reverse geo codes')]\n",
    "\n",
    "# reverse geo lookup to a df\n",
    "df_geo_data = parse_reverse_geo_lookup(results)\n",
    "\n",
    "# merge results geo lookop with main tgn dataset\n",
    "df_nl = (pd.merge(df_nl, df_geo_data, left_on='tgn_id', right_on='tgn_id_lookup', how='left')\n",
    "         .drop(columns=['tgn_id_lookup'])\n",
    "         )\n",
    "\n",
    "# parse tgn dataset into seperate cols\n",
    "df_nl = parse_parentstring(df_nl)\n",
    "df_nl = parse_broader_parentstring(df_nl)\n",
    "\n",
    "# change country code into country name to allign with tgn data\n",
    "df_nl['country_name_lookup'] = (df_nl['country_code_lookup']\n",
    "                                .apply(country_code_lookup)\n",
    "                                )\n",
    "\n",
    "del df_nl['country_code_lookup']\n",
    "\n",
    "# look up lat lons based on reverse geo lookup and return lat lons\n",
    "results_lookup = municipality_look_up(df_nl)\n",
    "\n",
    "# parse geo lookup into df\n",
    "df_results = parse_geo_lookup(results_lookup)\n",
    "\n",
    "# merge geo lookup with main tgn dataset\n",
    "df_nl = (pd.merge(df_nl, df_results, left_on='municipality_lookup', right_on='query_city_name', how='left')\n",
    "         .drop(columns=['query_city_name'])\n",
    "         )\n",
    "\n",
    "# creates a col with coordinate tuples for haversine distance measurements\n",
    "df_nl = data_haversine_tuple_creator(df_nl)\n",
    "\n",
    "# measures differences between two geo locations\n",
    "df_nl = haversine_distance_calculator(df_nl)\n",
    "\n",
    "df_nl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "find geo info based on city names: 100%|██████████| 50/50 [00:00<00:00, 1704.16it/s]\n"
     ]
    }
   ],
   "source": [
    "df_nl['lat_diff'] = ''\n",
    "for i in tqdm(range(len(df_nl)), total=len(df_nl), desc='find geo info based on city names'):\n",
    "    df_nl['lat_diff'].iloc[i] = float(df_nl['query_look_up'][i][0]) - float(df_nl['query_city_geo_data'][i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back-up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data_dumps/{filename_excel_export}.pickle', 'wb') as handle:\n",
    "    pickle.dump(df_nl, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geo location checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tgn_id</th>\n",
       "      <th>city_name</th>\n",
       "      <th>inferred_city_name</th>\n",
       "      <th>parentstring_province</th>\n",
       "      <th>parentstring_country</th>\n",
       "      <th>parentstring_continent</th>\n",
       "      <th>parentstring_world</th>\n",
       "      <th>broader_parentstring_country</th>\n",
       "      <th>broader_parentstring_continent</th>\n",
       "      <th>broader_parentstring_world</th>\n",
       "      <th>...</th>\n",
       "      <th>lon</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>query_look_up</th>\n",
       "      <th>municipality_lookup</th>\n",
       "      <th>country_name_lookup</th>\n",
       "      <th>query_city_city_info</th>\n",
       "      <th>query_city_geo_data</th>\n",
       "      <th>coordinates_looked_up</th>\n",
       "      <th>km_difference</th>\n",
       "      <th>lat_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://vocab.getty.edu/tgn/7270017</td>\n",
       "      <td>Aabeek</td>\n",
       "      <td>Limburg</td>\n",
       "      <td>Limburg</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Europe</td>\n",
       "      <td>World</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Europe</td>\n",
       "      <td>World</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>(51.25, 6)</td>\n",
       "      <td>(51.25, 6)</td>\n",
       "      <td>Leeuwen</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Leeuwen, Wageningen-Hoog, Wageningen, Gelderland, Nederland, 6704 AN, Nederland</td>\n",
       "      <td>(51.9826484, 5.6758503)</td>\n",
       "      <td>(51.21032, 5.99862)</td>\n",
       "      <td>88.73</td>\n",
       "      <td>-0.732648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>http://vocab.getty.edu/tgn/7006756</td>\n",
       "      <td>Arnemuiden</td>\n",
       "      <td>Zuid Beveland</td>\n",
       "      <td>Zuid Beveland</td>\n",
       "      <td>Zeeland</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Zeeland</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Europe</td>\n",
       "      <td>...</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>(51.5, 3.666667)</td>\n",
       "      <td>(51.5, 3.666667)</td>\n",
       "      <td>Veere</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Veere, Zeeland, Nederland</td>\n",
       "      <td>(51.55640385, 3.577269355747127)</td>\n",
       "      <td>(51.54833, 3.66667)</td>\n",
       "      <td>6.25</td>\n",
       "      <td>-0.056404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                tgn_id   city_name inferred_city_name  \\\n",
       "5   http://vocab.getty.edu/tgn/7270017      Aabeek            Limburg   \n",
       "26  http://vocab.getty.edu/tgn/7006756  Arnemuiden      Zuid Beveland   \n",
       "\n",
       "   parentstring_province parentstring_country parentstring_continent  \\\n",
       "5                Limburg          Netherlands                 Europe   \n",
       "26         Zuid Beveland              Zeeland            Netherlands   \n",
       "\n",
       "   parentstring_world broader_parentstring_country  \\\n",
       "5               World                  Netherlands   \n",
       "26             Europe                      Zeeland   \n",
       "\n",
       "   broader_parentstring_continent broader_parentstring_world  ...       lon  \\\n",
       "5                          Europe                      World  ...         6   \n",
       "26                    Netherlands                     Europe  ...  3.666667   \n",
       "\n",
       "         coordinates     query_look_up municipality_lookup  \\\n",
       "5         (51.25, 6)        (51.25, 6)             Leeuwen   \n",
       "26  (51.5, 3.666667)  (51.5, 3.666667)               Veere   \n",
       "\n",
       "   country_name_lookup  \\\n",
       "5          Netherlands   \n",
       "26         Netherlands   \n",
       "\n",
       "                                                               query_city_city_info  \\\n",
       "5   Leeuwen, Wageningen-Hoog, Wageningen, Gelderland, Nederland, 6704 AN, Nederland   \n",
       "26                                                        Veere, Zeeland, Nederland   \n",
       "\n",
       "                 query_city_geo_data coordinates_looked_up km_difference  \\\n",
       "5            (51.9826484, 5.6758503)   (51.21032, 5.99862)         88.73   \n",
       "26  (51.55640385, 3.577269355747127)   (51.54833, 3.66667)          6.25   \n",
       "\n",
       "    lat_diff  \n",
       "5  -0.732648  \n",
       "26 -0.056404  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nl[(df_nl['km_difference'] > 5) & (df_nl['query_look_up'].astype(str).str.contains('52') == False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other options\n",
    "- with geopy package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1670.64it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Nominatim' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m geocode \u001b[38;5;241m=\u001b[39m RateLimiter(geolocator, swallow_exceptions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, min_delay_seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, return_value_on_exception\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mcpu_count_laptop, thread_name_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthread\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 12\u001b[0m     locations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeocode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexactly_one\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf_nl\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmunicipality_lookup\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marte\\Miniconda3\\envs\\getty_ulan\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mc:\\Users\\marte\\Miniconda3\\envs\\getty_ulan\\Lib\\concurrent\\futures\\_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32mc:\\Users\\marte\\Miniconda3\\envs\\getty_ulan\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\marte\\Miniconda3\\envs\\getty_ulan\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marte\\Miniconda3\\envs\\getty_ulan\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\marte\\Miniconda3\\envs\\getty_ulan\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py:274\u001b[0m, in \u001b[0;36mRateLimiter.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acquire_request_slot()\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(res):\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn async awaitable has been passed to `RateLimiter`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `AsyncRateLimiter` instead, which supports awaitables.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         )\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Nominatim' object is not callable"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from pprint import pprint\n",
    "\n",
    "cpu_count_laptop = mp.cpu_count()\n",
    "geolocator = Nominatim(user_agent=\"Nancy Amandi\", timeout=10)\n",
    "geocode = RateLimiter(geolocator, swallow_exceptions=True, min_delay_seconds=0.1, return_value_on_exception=None) \n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=cpu_count_laptop, thread_name_prefix='thread') as e:\n",
    "    locations = list(e.map(partial(geocode, language='en', exactly_one=True), tqdm(list(set(df_nl[\"municipality_lookup\"]))), chunksize=100))\n",
    "    \n",
    "for i in range(len(locations)):\n",
    "    # pprint(locations[i].raw)\n",
    "    print(locations[i].raw['address']['country'])\n",
    "    # print(locations[i].raw['address']['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Nominatim' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 23\u001b[0m\n\u001b[0;32m     13\u001b[0m geocode \u001b[38;5;241m=\u001b[39m RateLimiter(geolocator, min_delay_seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# df_nl['new_location'] = df_nl['municipality_lookup'].progress_apply(geocode)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# geolocator = Nominatim(user_agent=\"Nancy Amandi\", timeout=10)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# geocode = RateLimiter(geolocator.reverse, min_delay_seconds=0.1)\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m df_nl[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_location\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_nl\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmunicipality_lookup\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeocode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexactly_one\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marte\\Miniconda3\\envs\\getty_ulan\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marte\\Miniconda3\\envs\\getty_ulan\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marte\\Miniconda3\\envs\\getty_ulan\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\marte\\Miniconda3\\envs\\getty_ulan\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marte\\Miniconda3\\envs\\getty_ulan\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\marte\\Miniconda3\\envs\\getty_ulan\\Lib\\site-packages\\pandas\\core\\apply.py:1496\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard.<locals>.curried\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurried\u001b[39m(x):\n\u001b[1;32m-> 1496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marte\\Miniconda3\\envs\\getty_ulan\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py:274\u001b[0m, in \u001b[0;36mRateLimiter.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acquire_request_slot()\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(res):\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn async awaitable has been passed to `RateLimiter`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `AsyncRateLimiter` instead, which supports awaitables.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         )\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Nominatim' object is not callable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "tqdm.pandas()\n",
    "\n",
    "# option 1\n",
    "geolocator = Nominatim(user_agent=\"geopy.geocoders.Nominatim\")\n",
    "geocode = RateLimiter(geolocator, min_delay_seconds=1)\n",
    "# df_nl['new_location'] = df_nl['municipality_lookup'].progress_apply(geocode)\n",
    "\n",
    "# option 2\n",
    "geolocator = Nominatim(user_agent=\"Nancy Amandi\", timeout=10)\n",
    "geocode = RateLimiter(geolocator.reverse, min_delay_seconds=0.1)\n",
    "df_nl['new_location'] = df_nl['municipality_lookup'].apply(geocode, language='en', exactly_one=True )\n",
    "\n",
    "# optione 3\n",
    "df_tgn['address'] = df_tgn.progress_apply(lambda row: geocode((row['lat.value'], row['long.value']), language='en', exactly_one=True), axis=1)\n",
    "df_tgn['country'] = df_tgn['address'].astype(str).str.split(',').str[-1]\n",
    "\n",
    "# option 4\n",
    "geolocator = Nominatim(user_agent=\"Nancy Amandi\", timeout= 10)\n",
    "rgeocode = RateLimiter(geolocator.reverse, min_delay_seconds=0.1)\n",
    "df_tgn[\"location\"] = df_tgn[\"coordinates\"].progress_apply(rgeocode)\n",
    "\n",
    "# func to work with try and except on multi-threaded geocode, doube apply\n",
    "def eval_results(x):\n",
    "    try:\n",
    "        return (x.latitude, x.longitude)\n",
    "    except:\n",
    "        return (None, None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "getty_ulan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
