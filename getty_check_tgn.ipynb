{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getty TGN | check on longitudes and latitudes by cross-checking other sources\n",
    "- 2024-05-18\n",
    "- Geo check on Getty TGN data fetched via SPARQL-endpoint\n",
    "- https://amandinancy16.medium.com/reverse-geocoding-with-geopy-c26cfb63f74c\n",
    "- V. Martens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating time stamps\n",
    "import time\n",
    "\n",
    "# importing files\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# progress bar\n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# regex module\n",
    "import re\n",
    "\n",
    "# for multi-threading\n",
    "from concurrent import futures\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import multiprocessing as mp\n",
    "\n",
    "# retrieve country names from country codes\n",
    "import pycountry\n",
    "\n",
    "# data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# back up files\n",
    "import pickle\n",
    "\n",
    "# retrieve various geo locations\n",
    "import reverse_geocoder as rg\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# measure distance between two geo points\n",
    "from haversine import haversine, Unit\n",
    "\n",
    "# save and dump\n",
    "import pickle\n",
    "\n",
    "# surpress, warnings, uhoohhhh\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# preferences\n",
    "# adjust pandas to show all cols\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest_file(filepath:str) -> str:\n",
    "    '''\n",
    "    loads created latest create file from a directory\n",
    "    args: string with filepath\n",
    "    returns: latest file from a list of files\n",
    "    '''\n",
    "\n",
    "    list_of_files = glob.glob(filepath)\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    print(latest_file)\n",
    "    \n",
    "    return latest_file\n",
    "\n",
    "def join_lats_lons(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    args: pd.DataFrame with lats and lons\n",
    "    returns: pd.DataFrame with corrected lats and lons and joined into one col \n",
    "    '''\n",
    "    \n",
    "    df['lat'] = df['lat'].str.replace('-.','-0.')\n",
    "    df['lon'] = df['lon'].str.replace('-.','-0.')\n",
    "    df['coordinates'] = list(zip(df['lat'], df['lon']))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_country(df:pd.DataFrame, i:int) -> list:\n",
    "    '''\n",
    "    args: pd.DataFrame() with coordinates column\n",
    "    returns: a list with dicts with geo locations, every dict contains keys with country name, 3 admin names, lat, lon\n",
    "    '''\n",
    "    \n",
    "    results = rg.search(df['coordinates'].iloc[i])\n",
    "\n",
    "    for item in results:\n",
    "        query = df['coordinates'].iloc[i]\n",
    "        tgn_id = df['tgn_id'].iloc[i]\n",
    "        country = item['cc']\n",
    "        looked_lat = item['lat']\n",
    "        looked_lon = item['lon']\n",
    "        looked_name = item['name']\n",
    "        \n",
    "    return [tgn_id, query, country, looked_lat, looked_lon, looked_name]\n",
    "\n",
    "def parse_reverse_geo_lookup(list_of_dicts:list) -> pd.DataFrame:\n",
    "    '''\n",
    "    args: a list with dicts with geo locations\n",
    "    returns: pd.DataFrame() with parsed geo locations\n",
    "    '''\n",
    "    \n",
    "    dfs = pd.DataFrame()\n",
    "\n",
    "    for coord_dict in list_of_dicts:\n",
    "        df = pd.DataFrame(coord_dict).T\n",
    "        dfs = pd.concat([dfs, df])\n",
    "    \n",
    "    dfs = dfs.rename(columns={0 : 'tgn_id_lookup',\n",
    "                              1 : 'query_look_up',\n",
    "                              2 : 'country_code_lookup', \n",
    "                              3 : 'lat_lookup',\n",
    "                              4 : 'lon_lookup', \n",
    "                              5 : 'municipality_lookup'})\n",
    "    \n",
    "    return dfs\n",
    "    \n",
    "def parse_parentstring(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    parses out info from parentstring\n",
    "    args: pd.DataFrame() with tgn parentstrings\n",
    "    returns: pd.DataFrame() with reordered and parsed columns\n",
    "    '''\n",
    "    \n",
    "    df['parentstring_province'] = (df['parentstring']\n",
    "                                    .str.split(',')\n",
    "                                    .str[0]\n",
    "                                    .str.strip())\n",
    "    \n",
    "    df['parentstring_country'] = (df['parentstring']\n",
    "                                    .str.split(',')\n",
    "                                    .str[1]\n",
    "                                    .str.strip())\n",
    "    \n",
    "    df['parentstring_continent'] = (df['parentstring']\n",
    "                                    .str.split(',')\n",
    "                                    .str[2]\n",
    "                                    .str.strip())  \n",
    "    \n",
    "    df['parentstring_world'] = (df['parentstring']\n",
    "                                    .str.split(',')\n",
    "                                    .str[3]\n",
    "                                    .str.strip())  \n",
    "    \n",
    "    df = df[['tgn_id', 'city_name', 'inferred_city_name', 'parentstring_province',\n",
    "             'parentstring_country', 'parentstring_continent', 'parentstring_world',\n",
    "             'broader_parentstring', 'lat', 'lon', 'coordinates', 'query_look_up',\n",
    "             'country_code_lookup', 'lat_lookup', 'lon_lookup',\n",
    "             'municipality_lookup']]\n",
    "    \n",
    "    return df    \n",
    "\n",
    "def parse_broader_parentstring(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    parses out info from broader parentstring\n",
    "    args: pd.DataFrame() with tgn broader parentstrings\n",
    "    returns: pd.DataFrame() with reordered and parsed columns\n",
    "    '''\n",
    "    \n",
    "    df['broader_parentstring_country'] = (df['broader_parentstring']\n",
    "                                    .str.split()\n",
    "                                    .str[0]\n",
    "                                    .str.replace(',','')\n",
    "                                    .str.strip())\n",
    "    \n",
    "    df['broader_parentstring_continent'] = (df['broader_parentstring']\n",
    "                                    .str.split()\n",
    "                                    .str[1]\n",
    "                                    .str.replace(',','')\n",
    "                                    .str.strip())  \n",
    "    \n",
    "    df['broader_parentstring_world'] = (df['broader_parentstring']\n",
    "                                    .str.split()\n",
    "                                    .str[2]\n",
    "                                    .str.replace(',','')\n",
    "                                    .str.strip())  \n",
    "    \n",
    "    df = df[['tgn_id', 'city_name', 'inferred_city_name', 'parentstring_province',\n",
    "       'parentstring_country', 'parentstring_continent', 'parentstring_world',\n",
    "       'broader_parentstring_country', 'broader_parentstring_continent',\n",
    "       'broader_parentstring_world', 'lat', 'lon', 'coordinates', 'query_look_up',\n",
    "       'country_code_lookup', 'lat_lookup', 'lon_lookup', 'municipality_lookup']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def country_code_lookup(country_code:str) -> str:\n",
    "    '''\n",
    "    \n",
    "    retrieves countryname from countrycode\n",
    "    args: string with countrycode\n",
    "    returns: returns country name\n",
    "    '''\n",
    "    \n",
    "    return pycountry.countries.get(alpha_2=country_code).name\n",
    "\n",
    "def municipality_look_up(df:pd.DataFrame) -> dict:\n",
    "    '''\n",
    "    pd.DataFrame with city names retrieves city info, lats, lons\n",
    "    args: pd.DataFrame with city name/municipalities\n",
    "    returns: a dict with city names as keys and location info and lats, lons as values\n",
    "    '''\n",
    "    \n",
    "    geolocator = Nominatim(user_agent=\"Nancy Amandi\", timeout=10)\n",
    "    \n",
    "    dict_locs = {}\n",
    "    \n",
    "    for i in tqdm(range(len(df)), total=len(df), desc='find geo info, based on city names'):\n",
    "        \n",
    "        # lambda query: geolocator.geocode(\"%s, Cleveland OH\" % query)\n",
    "        \n",
    "        dict_locs[df['municipality_lookup'].iloc[i]] = lambda query: geolocator.geocode(f\"{df['municipality_lookup'].iloc[i]}, NL\")\n",
    "    \n",
    "    return dict_locs\n",
    "\n",
    "def parse_geo_lookup(results_lookup:dict) -> pd.DataFrame:\n",
    "    '''\n",
    "    parses looked up geo data into a pd.DataFrame\n",
    "    args: a dict with looked up geo locations based on city names\n",
    "    returns: a pd.DataFrame with city names, lat-lons\n",
    "    '''\n",
    "    \n",
    "    df_parsed_geo = (pd.DataFrame(results_lookup)\n",
    "                    .T.reset_index()\n",
    "                    .rename(columns={'index':'query_city_name',\n",
    "                                    0 : 'query_city_city_info',\n",
    "                                    1 : 'query_city_geo_data'}))\n",
    "    \n",
    "    return df_parsed_geo\n",
    "\n",
    "def data_haversine_tuple_creator(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    args: pd.DataFrame with seperate lat lon\n",
    "    returns: pd.Dataframe with a tuple of lat lon in one col\n",
    "    '''\n",
    "    \n",
    "    df['coordinates_looked_up'] = list(zip(df['lat_lookup'].astype(float), df['lon_lookup'].astype(float)))\n",
    "    df = df.drop(columns=['lat_lookup', 'lon_lookup'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def haversine_distance_calculator(df) -> pd.DataFrame:\n",
    "    '''\n",
    "    measures distance between two tuples containing two geo points each \n",
    "    args: a pd.DataFrame with two columns containing tuples with floats\n",
    "    returns: a pd.DataFrame with a column that has measured the difference in kms between two tuples with geo points\n",
    "    '''\n",
    "    \n",
    "    df['km_difference'] = '' \n",
    "    \n",
    "    for i in tqdm(range(len(df)), total=len(df), desc='calculate diff between geo points'):\n",
    "        df['km_difference'].iloc[i] = round(haversine(df['query_city_geo_data'].iloc[i], df['coordinates_looked_up'].iloc[i], unit=Unit.KILOMETERS),2)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def lon_lat_diff(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    diff betweeon geo points\n",
    "    args: pd.DataFrame with two lats and two lons as a lats + lons tuple\n",
    "    returns: pd.DataFrame pd.DataFrame with diff between lats and lons combination\n",
    "    '''\n",
    "    \n",
    "    df['lat_diff'] = ''\n",
    "    df['lon_diff'] = ''\n",
    "\n",
    "    for i in tqdm(range(len(df)), total=len(df), desc='calculate lats and lons differences'):\n",
    "        df['lat_diff'].iloc[i] = float(df['query_look_up'][i][0]) - float(df['query_city_geo_data'][i][0])\n",
    "        df['lon_diff'].iloc[i] = float(df['query_look_up'][i][1]) - float(df['query_city_geo_data'][i][1])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants + user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_check \n",
    "country = 'Netherlands'\n",
    "continent = 'Europe'\n",
    "\n",
    "# create back up filename for a pickle\n",
    "time_stamp = time.strftime('%Y%m%d-%H%M%S')\n",
    "filename_df_errors = f'{time_stamp}_df_errors_tgn.pickle'\n",
    "\n",
    "# create back up filename for a pickle\n",
    "time_stamp = time.strftime('%Y%m%d-%H%M%S')\n",
    "filename_df_lod_results = f'{time_stamp}_df_lod_results_tgn.pickle'\n",
    "\n",
    "# create back up filename for a pickle\n",
    "time_stamp = time.strftime('%Y%m%d-%H%M%S')\n",
    "filename_excel_export = f'{time_stamp}_{country}_loc_check_TGN.xlsx'\n",
    "\n",
    "print(f\"{filename_df_errors}, {filename_df_lod_results}, {filename_excel_export}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_picke_file = load_latest_file('data_dumps/*tgn_country.pickle')\n",
    "\n",
    "# Open the file in binary mode\n",
    "with open(latest_picke_file, 'rb') as file:\n",
    "      \n",
    "    # Call load method to deserialze\n",
    "    df_tgn = pickle.load(file)\n",
    "    \n",
    "# enrich lats, lons\n",
    "df_tgn = join_lats_lons(df_tgn)\n",
    "df_tgn.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset data\n",
    "df_nl = df_tgn[(df_tgn['broader_parentstring'].str.contains(f'{country}') == True)]\n",
    "df_europe = df_tgn[(df_tgn['broader_parentstring'].str.contains(f'{europe}') == True)]\n",
    "df_nl.shape, df_europe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geo data-check\n",
    " 1. Reverse city look-up on geo lats + lons \n",
    " 1. Retrieve lats, lons based on reversed look-up\n",
    " 1. Compare distances between two geo-points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import multiprocessing as mp\n",
    "pools = mp.cpu_count()\n",
    "\n",
    "# Start pool\n",
    "thread_pool = ThreadPoolExecutor(max_workers=pools, thread_name_prefix = 'thread')\n",
    "\n",
    "# reate futures\n",
    "futures = [thread_pool.submit(get_country, df_nl, i) for i in range(len())]\n",
    "\n",
    "# submit tasks\n",
    "results = [future.result() for future in tqdm(futures, total=len(futures), desc='find reverse geo codes')]\n",
    "\n",
    "# reverse geo lookup to a df\n",
    "df_geo_data = parse_reverse_geo_lookup(results)\n",
    "\n",
    "# merge results geo lookop with main tgn dataset\n",
    " = (pd.merge(df_nl, df_geo_data, left_on='tgn_id', right_on='tgn_id_lookup', how='left')\n",
    "         .drop(columns=['tgn_id_lookup'])\n",
    "         )\n",
    "\n",
    "# parse tgn dataset into seperate cols\n",
    "df_nl = parse_parentstring(df_nl)\n",
    "df_nl = parse_broader_parentstring(df_nl)\n",
    "\n",
    "# change country code into country name to allign with tgn data\n",
    "df_nl['country_name_lookup'] = (df_nl['country_code_lookup']\n",
    "                                .apply(country_code_lookup)\n",
    "                                )\n",
    "\n",
    "del df_nl['country_code_lookup']\n",
    "\n",
    "# look up lat lons based on reverse geo lookup and return lat lons\n",
    "results_lookup = municipality_look_up(df_nl)\n",
    "\n",
    "# parse geo lookup into df\n",
    "df_results = parse_geo_lookup(results_lookup)\n",
    "\n",
    "# merge geo lookup with main tgn dataset\n",
    "df_nl = (pd.merge(df_nl, df_results, left_on='municipality_lookup', right_on='query_city_name', how='left')\n",
    "         .drop(columns=['query_city_name'])\n",
    "         )\n",
    "\n",
    "# creates a col with coordinate tuples for haversine distance measurements\n",
    "df_nl = data_haversine_tuple_creator(df_nl)\n",
    "\n",
    "# measures differences between two geo locations\n",
    "df_nl = haversine_distance_calculator(df_nl)\n",
    "\n",
    "# diff between lots and lats combinations\n",
    "df_nl = lon_lat_diff(df_nl)\n",
    "\n",
    "df_nl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nl = lon_lat_diff(df_nl)\n",
    "df_nl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back-up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data_dumps/{filename_excel_export}.pickle', 'wb') as handle:\n",
    "    pickle.dump(df_nl, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geo location checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nl[(df_nl['country_name_lookup'] != 'Netherlands' ) & (df_nl['km_difference'] > 5)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nl[(df_nl['km_difference'] > 5) & ((df_nl['lat_diff'] >= 0.5) & (df_nl['lat_diff'] < 1.5))].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other options\n",
    "- with geopy package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from pprint import pprint\n",
    "\n",
    "cpu_count_laptop = mp.cpu_count()\n",
    "geolocator = Nominatim(user_agent=\"Nancy Amandi\", timeout=10)\n",
    "geocode = RateLimiter(geolocator, swallow_exceptions=True, min_delay_seconds=0.1, return_value_on_exception=None) \n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=cpu_count_laptop, thread_name_prefix='thread') as e:\n",
    "    locations = list(e.map(partial(geocode, language='en', exactly_one=True), tqdm(list(set(df_nl[\"municipality_lookup\"]))), chunksize=100))\n",
    "    \n",
    "for i in range(len(locations)):\n",
    "    # pprint(locations[i].raw)\n",
    "    print(locations[i].raw['address']['country'])\n",
    "    # print(locations[i].raw['address']['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "tqdm.pandas()\n",
    "\n",
    "# option 1\n",
    "geolocator = Nominatim(user_agent=\"geopy.geocoders.Nominatim\")\n",
    "geocode = RateLimiter(geolocator, min_delay_seconds=1)\n",
    "# df_nl['new_location'] = df_nl['municipality_lookup'].progress_apply(geocode)\n",
    "\n",
    "# option 2\n",
    "geolocator = Nominatim(user_agent=\"Nancy Amandi\", timeout=10)\n",
    "geocode = RateLimiter(geolocator.reverse, min_delay_seconds=0.1)\n",
    "df_nl['new_location'] = df_nl['municipality_lookup'].apply(geocode, language='en', exactly_one=True )\n",
    "\n",
    "# optione 3\n",
    "df_tgn['address'] = df_tgn.progress_apply(lambda row: geocode((row['lat.value'], row['long.value']), language='en', exactly_one=True), axis=1)\n",
    "df_tgn['country'] = df_tgn['address'].astype(str).str.split(',').str[-1]\n",
    "\n",
    "# option 4\n",
    "geolocator = Nominatim(user_agent=\"Nancy Amandi\", timeout= 10)\n",
    "rgeocode = RateLimiter(geolocator.reverse, min_delay_seconds=0.1)\n",
    "df_tgn[\"location\"] = df_tgn[\"coordinates\"].progress_apply(rgeocode)\n",
    "\n",
    "# func to work with try and except on multi-threaded geocode, doube apply\n",
    "def eval_results(x):\n",
    "    try:\n",
    "        return (x.latitude, x.longitude)\n",
    "    except:\n",
    "        return (None, None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "getty_ulan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
